{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c0ed4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV = \"data/gesamte_akte.csv\"\n",
    "file = open(CSV, \"r\", encoding=\"utf-8\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dcb78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = file.splitlines()\n",
    "raw_matrix = [[(c if (c:=cell.strip()) != \"\" else None) for cell in line.split(\";\")]\n",
    "              for line in file.splitlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b02a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if all page-headers are followed by an empty line => Sieht danach aus\n",
    "for i, row in enumerate(raw_matrix):\n",
    "    if all(c is None for c in row):\n",
    "        # print(raw_matrix[i-1] if i > 0 else None)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5539991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gibt alle Labor-Blöcke aus\n",
    "labs_sections = []\n",
    "for i, row in enumerate(raw_matrix):\n",
    "    if (\n",
    "        row and len(row) > 0\n",
    "        and isinstance(row[0], str)\n",
    "        and row[0].startswith(\"Labor:\")\n",
    "        and (i + 1) < len(raw_matrix)\n",
    "        and raw_matrix[i+1] is not None\n",
    "        and len(raw_matrix[i+1]) > 20\n",
    "    ):\n",
    "        labs_sections.append(row[0])\n",
    "\n",
    "labs_sections = list(dict.fromkeys(labs_sections))\n",
    "# labs_sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da30f870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erste 5 Zeilen NACH jeder Labor-Section ausgeben\n",
    "for labs_section in labs_sections:\n",
    "    # print(labs_section)\n",
    "    for i, row in enumerate(raw_matrix):\n",
    "        if row and row[0] == labs_section:\n",
    "            for nxt in raw_matrix[i+1:i+6]:\n",
    "                # print(len(nxt))\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c152eb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bereinigt die csv von den ganzen page-headers\n",
    "headers = []\n",
    "skip = set()\n",
    "skip.add(len(lines)-1)\n",
    "for i, line in enumerate(lines):\n",
    "    if line.lstrip().__contains__(\"Ausdruck: Gesamte Akte\"):\n",
    "        headers.append(i)\n",
    "    if line.lstrip().__contains__(\"Bei aktuell laufenden Statusmodulen\"):\n",
    "        skip.add(i)\n",
    "\n",
    "for j, h in enumerate(headers):\n",
    "    # Header-Zeile + die nächsten 7 Zeilen überspringen\n",
    "    skip.update(range(h, min(h + 8, len(lines))))\n",
    "    # Zusätzlich: die Footer-Zeile davor (außer beim allerersten Header)\n",
    "    if j > 0 and h - 1 >= 0:\n",
    "        skip.add(h - 1)\n",
    "\n",
    "out_path = \"data/gesamte_akte_cleared.csv\"\n",
    "with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for i, line in enumerate(lines):\n",
    "        if i in skip:\n",
    "            continue\n",
    "        f.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bcf282",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = {}\n",
    "for row in raw_matrix:\n",
    "    if row and row[0] is not None:\n",
    "        counter[row[0]] = counter.get(row[0], 0) + 1\n",
    "uniq_dict = {c: n for c, n in counter.items() if n == 1}\n",
    "# uniq_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac4541a",
   "metadata": {},
   "source": [
    "# Datenextraktion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ce662b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_CLEAR = \"data/gesamte_akte_cleared.csv\"\n",
    "file_clear = open(CSV_CLEAR, \"r\", encoding=\"utf-8\").read()\n",
    "lines_clear = file_clear.splitlines()\n",
    "matrix = [[(c if (c:=cell.strip()) != \"\" else None) for cell in line.split(\";\")]\n",
    "              for line in file_clear.splitlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62f7797",
   "metadata": {},
   "outputs": [],
   "source": [
    "from services.headers import headers\n",
    "# headers\n",
    "\n",
    "header_list = [x for v in headers.values() for x in v]\n",
    "# header_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e9d6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def check_row(row):\n",
    "    row_type = None\n",
    "    date_re = re.compile(r\"\\d{2}\\.\\d{2}\\.\\d{2} \\d{2}:\\d{2}\")\n",
    "\n",
    "    if row[0] in header_list:\n",
    "        return \"header\"\n",
    "    if "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568b0a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sammelt Zeilenblöcke nach jedem Header k mit gleicher Zeilenlänge bis zum nächsten Header\n",
    "dfs = {k: [] for k in header_list}\n",
    "\n",
    "for k in header_list:\n",
    "    line = None\n",
    "    # Header-Zeile finden\n",
    "    for i, l in enumerate(matrix):\n",
    "        if l and len(l) > 0 and l[0] == k:\n",
    "            line = i\n",
    "            break\n",
    "    # nichts gefunden\n",
    "    if line is None:\n",
    "        continue\n",
    "\n",
    "    header_line_len = len(matrix[line])  # Länge der Header-Zeile als Referenz (oder nimm matrix[line+1] falls gewünscht)\n",
    "\n",
    "    # nachfolgende Zeilen einsammeln\n",
    "    while True:\n",
    "        line += 1\n",
    "        if line >= len(matrix):\n",
    "            break\n",
    "        row = matrix[line]\n",
    "\n",
    "        # Abbruch wenn nächste Header-Zeile beginnt\n",
    "        if row and len(row) > 0 and isinstance(row[0], str) and (row[0] in header_list):\n",
    "            break\n",
    "\n",
    "        # Abbruch wenn sich die Spaltenanzahl ändert\n",
    "        if len(row) != header_line_len:\n",
    "            ##################### Hier weiter #####################\n",
    "            ##################### Hier weiter #####################\n",
    "            ##################### Hier weiter #####################\n",
    "            ##################### Hier weiter #####################\n",
    "            # Hier prüfen, ob eine neue Datumszeile mit unterschiedlicher Anzahl an Spalten begonnen wurde\n",
    "            print(\"len error\")\n",
    "            break\n",
    "\n",
    "        dfs[k].append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06149d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# das sagt chat-GPT dazu\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# deine Header-Definition\n",
    "headers = {\n",
    "    \"Vitaldaten\": ['Online erfasste Vitaldaten', 'Manuell erfasste Vitaldaten'],\n",
    "    \"Respiratordaten\": ['Online erfasste Respiratorwerte', 'Beatmung', 'Manuell erfasste Respiratorwerte'],\n",
    "    \"Labor\": [\n",
    "        'Labor: Blutgase arteriell','Labor: Blutgase venös','Labor: Blutgase gv','Labor: Blutgase unspez.',\n",
    "        'Labor: Blutbild','Labor: Differentialblutbild','Labor: Blutgruppe','Labor: Gerinnung',\n",
    "        'Labor: TEG','Labor: TAT','Labor: Enzyme','Labor: Retention','Labor: Lipide','Labor: Proteine',\n",
    "        'Labor: Elektrolyte','Labor: Blutzucker','Labor: Klinische Chemie','Labor: Medikamentenspiegel',\n",
    "        'Labor: Schilddrüse','Labor: Serologie/Infektion'],\n",
    "    \"Dokumentation\": [\"Arztnotizen\", \"Pflegenotizen\"],\n",
    "    \"Medikamentengaben\": [\"Medikamentengabe\"],\n",
    "    \"Katheter\": [\"Katheter\"],\n",
    "    \"Drainagen\": [\"Drainagen\"],\n",
    "    \"Wunden\": [\"Wunden\"],\n",
    "    \"ALLE Patientendaten\": [\"ALLE Patientendaten\"]\n",
    "}\n",
    "\n",
    "# Regex für Datum\n",
    "date_re = re.compile(r\"\\d{2}\\.\\d{2}\\.\\d{2} \\d{2}:\\d{2}\")\n",
    "\n",
    "# CSV einlesen (roh, ohne Header)\n",
    "import pandas as pd\n",
    "\n",
    "raw_df = pd.read_csv(\n",
    "    \"data/gesamte_akte_cleared.csv\",\n",
    "    sep=\";\",          # oder sep=\"|\" testen, je nach Export\n",
    "    engine=\"python\",  # langsamer, aber robuster\n",
    "    on_bad_lines=\"warn\",  # oder \"skip\"\n",
    ")\n",
    "matrix = raw_df.fillna(\"\").values.tolist()\n",
    "\n",
    "records = []\n",
    "current_block = None\n",
    "timestamps = []\n",
    "\n",
    "for row in matrix:\n",
    "    row = [str(c).strip() for c in row]\n",
    "\n",
    "    # 1) Blockanfang?\n",
    "    if any(row[0] in vals for vals in headers.values()):\n",
    "        # Bestimme Blocktyp\n",
    "        for k, vals in headers.items():\n",
    "            if row[0] in vals:\n",
    "                current_block = k\n",
    "                timestamps = []\n",
    "                break\n",
    "        continue\n",
    "\n",
    "    # 2) Headerzeile (enthält Zeitstempel)?\n",
    "    if sum(bool(date_re.match(c)) for c in row if c) > 2:\n",
    "        timestamps = [pd.to_datetime(c, format=\"%d.%m.%y %H:%M\") for c in row if date_re.match(c)]\n",
    "        continue\n",
    "\n",
    "    # 3) Datenzeile innerhalb eines Blocks\n",
    "    if current_block and timestamps and row[2]:\n",
    "        param = row[2]\n",
    "        values = [c for c in row if c not in (\"\", None) and not date_re.match(str(c))]\n",
    "        # Mapping timestamp <-> values\n",
    "        for t, v in zip(timestamps, values[-len(timestamps):]):\n",
    "            records.append({\n",
    "                \"block\": current_block,\n",
    "                \"parameter\": param,\n",
    "                \"timestamp\": t,\n",
    "                \"value\": v\n",
    "            })\n",
    "\n",
    "# Ergebnis-DF\n",
    "df = pd.DataFrame(records)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decc10fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[10000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3f5e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_string = datastring.splitlines()\n",
    "test_lists = [[(c if (c:=cell.strip()) != \"\" else None) for cell in line.split(\";\")]\n",
    "              for line in datastring.splitlines()]\n",
    "\n",
    "[len(l) for l in test_lists]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999ed316",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"Kategorie\"] == \"Labor: Schilddrüse\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a30b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ich finde den Ansatz gar nicht schlecht, die einzelnen Daten wie von chatGPT vorgeschlagen als Blöcke/Parameter/Datum/Value zu speichern.\n",
    "## Dafür muss ich eigentlich nur erst die Blöcke erkennen, dann die Zeilen mit dem Datum erkennen, das in Datetime parsen & die untergeordneten parameter einpassen"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clean-mlife (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
